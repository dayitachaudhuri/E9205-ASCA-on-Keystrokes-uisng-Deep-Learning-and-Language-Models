{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AudioKeystrokeDataset.AudioKeystrokeDataset import AudioKeystrokeDataset\n",
    "# from CoatNet.CoatNet import CoAtNet\n",
    "# from CoatNet.Trainer import Trainer\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoatNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    \"\"\"\n",
    "    A Mobile Inverted Bottleneck Convolution (MBConv) block.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, expand_ratio=4):\n",
    "        super(MBConv, self).__init__()\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "        self.use_residual = (stride == 1 and in_channels == out_channels)\n",
    "        self.conv = nn.Sequential(\n",
    "            # Expansion phase\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1), \n",
    "            # Depthwise convolution\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride,\n",
    "                      padding=kernel_size // 2, groups=hidden_dim, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Projection phase\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        if self.use_residual:\n",
    "            return out + x\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A transformer block that first normalizes and then applies multi-head attention \n",
    "    followed by a feed-forward network.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is expected to have shape (B, C, H, W)\n",
    "        B, C, H, W = x.shape\n",
    "        # Flatten spatial dimensions: (S, B, C) where S = H*W\n",
    "        x_flat = x.flatten(2).permute(2, 0, 1)\n",
    "        # Apply multi-head self-attention with residual connection\n",
    "        attn_out, _ = self.attn(self.norm1(x_flat), self.norm1(x_flat), self.norm1(x_flat))\n",
    "        x_flat = x_flat + self.dropout(attn_out)\n",
    "        # Feed-forward network with residual connection\n",
    "        ff_out = self.ff(self.norm2(x_flat))\n",
    "        x_flat = x_flat + self.dropout(ff_out)\n",
    "        # Reshape back to (B, C, H, W)\n",
    "        x = x_flat.permute(1, 2, 0).view(B, C, H, W)\n",
    "        return x\n",
    "\n",
    "##############################################\n",
    "# Define the Modified CoAtNet Architecture\n",
    "##############################################\n",
    "\n",
    "class CoAtNet(nn.Module):\n",
    "    def __init__(self, num_classes=36, in_channels=1):\n",
    "        super(CoAtNet, self).__init__()\n",
    "        # Stem: initial convolution to reduce spatial dimensions\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # Stage 1: Convolutional blocks (MBConv)\n",
    "        self.stage1 = nn.Sequential(\n",
    "            MBConv(32, 64, stride=2),\n",
    "            MBConv(64, 64, stride=1)\n",
    "        )\n",
    "        # Stage 2: Transformer blocks\n",
    "        self.stage2 = nn.Sequential(\n",
    "            TransformerBlock(embed_dim=64, num_heads=4),\n",
    "            TransformerBlock(embed_dim=64, num_heads=4)\n",
    "        )\n",
    "        # Stage 3: Further convolutional blocks (MBConv)\n",
    "        self.stage3 = nn.Sequential(\n",
    "            MBConv(64, 128, stride=2),\n",
    "            MBConv(128, 128, stride=1)\n",
    "        )\n",
    "        # Classification head: global pooling and a linear classifier\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x expected shape: (B, 1, H, W)\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, criterion, optimizer, device, \n",
    "                 scheduler=None, early_stopping_patience=10):\n",
    "        self.model = model.to(device)\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.scheduler = scheduler \n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data, targets in self.train_loader:\n",
    "            data, targets = data.to(self.device), targets.to(self.device)\n",
    "            if len(data.shape) == 3:  \n",
    "                data = data.unsqueeze(1)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(data)\n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            running_loss += loss.item() * data.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data, targets in self.val_loader:\n",
    "                data, targets = data.to(self.device), targets.to(self.device)\n",
    "                if len(data.shape) == 3:\n",
    "                    data = data.unsqueeze(1)\n",
    "                outputs = self.model(data)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "                running_loss += loss.item() * data.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += targets.size(0)\n",
    "                correct += (predicted == targets).sum().item()\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = correct / total\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def train(self, num_epochs, save_path=None, resume=False, load_path=None):\n",
    "        start_epoch = 0\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        \n",
    "        if resume and load_path and os.path.exists(load_path):\n",
    "            checkpoint = torch.load(load_path)\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            start_epoch = checkpoint.get('epoch', 0)\n",
    "            best_val_acc = checkpoint.get('best_val_acc', 0.0)\n",
    "            print(f\"Resuming training from epoch {start_epoch}\")\n",
    "            \n",
    "        for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            val_loss, val_acc = self.validate()\n",
    "            print(f\"Epoch {epoch+1}/{start_epoch + num_epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            # Step the scheduler if provided (using val_acc as the metric)\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step(val_acc)\n",
    "            \n",
    "            # Early stopping check based on validation accuracy\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                if save_path:\n",
    "                    torch.save({\n",
    "                        'epoch': epoch + 1,\n",
    "                        'model_state_dict': self.model.state_dict(),\n",
    "                        'best_val_acc': best_val_acc\n",
    "                    }, save_path)\n",
    "                    print(f\"Saved best model at epoch {epoch+1} with Val Acc: {best_val_acc:.4f}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= self.early_stopping_patience:\n",
    "                    print(f\"Early stopping triggered at epoch {epoch+1}. No improvement in validation accuracy for {self.early_stopping_patience} epochs.\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\" \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "DATASET_PATH = config['DATASET_PATH']['all']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Dataset fot Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Audio Files: 100%|██████████| 412/412 [04:51<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 14421 keystroke samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = AudioKeystrokeDataset(DATASET_PATH, full_dataset=True)\n",
    "print(f\"Dataset contains {len(dataset)} keystroke samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 11536\n",
      "Validation dataset size: 1442\n",
      "Testing dataset size: 1443\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "val_dataset_size = len(val_dataset)\n",
    "val_size = int(0.5 * val_dataset_size)\n",
    "test_size = val_dataset_size - val_size\n",
    "val_dataset, test_dataset = random_split(val_dataset, [val_size, test_size])\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Testing dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_classes = len(set(dataset.get_labels()))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = CoAtNet(num_classes=len(dataset.label2idx), in_channels=1)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "trainer = Trainer(model, train_loader, val_loader, criterion, optimizer, device, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 4.2848, Train Acc: 0.0189 | Val Loss: 4.2388, Val Acc: 0.0229\n",
      "Saved best model at epoch 1 with Val Acc: 0.0229\n",
      "Epoch 2/100 | Train Loss: 4.1334, Train Acc: 0.0370 | Val Loss: 4.0254, Val Acc: 0.0479\n",
      "Saved best model at epoch 2 with Val Acc: 0.0479\n",
      "Epoch 3/100 | Train Loss: 3.8140, Train Acc: 0.0719 | Val Loss: 3.6795, Val Acc: 0.0818\n",
      "Saved best model at epoch 3 with Val Acc: 0.0818\n",
      "Epoch 4/100 | Train Loss: 3.4052, Train Acc: 0.1249 | Val Loss: 3.0912, Val Acc: 0.1574\n",
      "Saved best model at epoch 4 with Val Acc: 0.1574\n",
      "Epoch 5/100 | Train Loss: 3.0433, Train Acc: 0.1808 | Val Loss: 2.7672, Val Acc: 0.2178\n",
      "Saved best model at epoch 5 with Val Acc: 0.2178\n",
      "Epoch 6/100 | Train Loss: 2.6948, Train Acc: 0.2347 | Val Loss: 2.5915, Val Acc: 0.2587\n",
      "Saved best model at epoch 6 with Val Acc: 0.2587\n",
      "Epoch 7/100 | Train Loss: 2.4232, Train Acc: 0.2961 | Val Loss: 2.2753, Val Acc: 0.3155\n",
      "Saved best model at epoch 7 with Val Acc: 0.3155\n",
      "Epoch 8/100 | Train Loss: 2.1893, Train Acc: 0.3559 | Val Loss: 2.0425, Val Acc: 0.3835\n",
      "Saved best model at epoch 8 with Val Acc: 0.3835\n",
      "Epoch 9/100 | Train Loss: 1.9990, Train Acc: 0.4050 | Val Loss: 1.9966, Val Acc: 0.3883\n",
      "Saved best model at epoch 9 with Val Acc: 0.3883\n",
      "Epoch 10/100 | Train Loss: 1.8289, Train Acc: 0.4441 | Val Loss: 1.8984, Val Acc: 0.4161\n",
      "Saved best model at epoch 10 with Val Acc: 0.4161\n",
      "Epoch 11/100 | Train Loss: 1.6713, Train Acc: 0.4955 | Val Loss: 1.6419, Val Acc: 0.4868\n",
      "Saved best model at epoch 11 with Val Acc: 0.4868\n",
      "Epoch 12/100 | Train Loss: 1.5409, Train Acc: 0.5253 | Val Loss: 1.5102, Val Acc: 0.5319\n",
      "Saved best model at epoch 12 with Val Acc: 0.5319\n",
      "Epoch 13/100 | Train Loss: 1.4020, Train Acc: 0.5663 | Val Loss: 1.7015, Val Acc: 0.4785\n",
      "Epoch 14/100 | Train Loss: 1.3223, Train Acc: 0.5907 | Val Loss: 1.3584, Val Acc: 0.5707\n",
      "Saved best model at epoch 14 with Val Acc: 0.5707\n",
      "Epoch 15/100 | Train Loss: 1.2136, Train Acc: 0.6194 | Val Loss: 1.3203, Val Acc: 0.5985\n",
      "Saved best model at epoch 15 with Val Acc: 0.5985\n",
      "Epoch 16/100 | Train Loss: 1.1588, Train Acc: 0.6332 | Val Loss: 1.3268, Val Acc: 0.5874\n",
      "Epoch 17/100 | Train Loss: 1.0785, Train Acc: 0.6576 | Val Loss: 1.1911, Val Acc: 0.6325\n",
      "Saved best model at epoch 17 with Val Acc: 0.6325\n",
      "Epoch 18/100 | Train Loss: 1.0252, Train Acc: 0.6762 | Val Loss: 1.2000, Val Acc: 0.6394\n",
      "Saved best model at epoch 18 with Val Acc: 0.6394\n",
      "Epoch 19/100 | Train Loss: 0.9628, Train Acc: 0.6914 | Val Loss: 1.1866, Val Acc: 0.6366\n",
      "Epoch 20/100 | Train Loss: 0.8918, Train Acc: 0.7181 | Val Loss: 1.2514, Val Acc: 0.6241\n",
      "Epoch 21/100 | Train Loss: 0.8631, Train Acc: 0.7240 | Val Loss: 1.2318, Val Acc: 0.6311\n",
      "Epoch 22/100 | Train Loss: 0.8104, Train Acc: 0.7360 | Val Loss: 1.2963, Val Acc: 0.6117\n",
      "Epoch 23/100 | Train Loss: 0.7710, Train Acc: 0.7508 | Val Loss: 1.1833, Val Acc: 0.6477\n",
      "Saved best model at epoch 23 with Val Acc: 0.6477\n",
      "Epoch 24/100 | Train Loss: 0.7550, Train Acc: 0.7570 | Val Loss: 1.2120, Val Acc: 0.6429\n",
      "Epoch 25/100 | Train Loss: 0.7108, Train Acc: 0.7694 | Val Loss: 1.1995, Val Acc: 0.6512\n",
      "Saved best model at epoch 25 with Val Acc: 0.6512\n",
      "Epoch 26/100 | Train Loss: 0.6695, Train Acc: 0.7836 | Val Loss: 1.1610, Val Acc: 0.6650\n",
      "Saved best model at epoch 26 with Val Acc: 0.6650\n",
      "Epoch 27/100 | Train Loss: 0.6656, Train Acc: 0.7809 | Val Loss: 1.1618, Val Acc: 0.6845\n",
      "Saved best model at epoch 27 with Val Acc: 0.6845\n",
      "Epoch 28/100 | Train Loss: 0.6170, Train Acc: 0.7982 | Val Loss: 1.0952, Val Acc: 0.6755\n",
      "Epoch 29/100 | Train Loss: 0.5980, Train Acc: 0.7998 | Val Loss: 1.1344, Val Acc: 0.6824\n",
      "Epoch 30/100 | Train Loss: 0.5822, Train Acc: 0.8078 | Val Loss: 1.0621, Val Acc: 0.6872\n",
      "Saved best model at epoch 30 with Val Acc: 0.6872\n",
      "Epoch 31/100 | Train Loss: 0.5542, Train Acc: 0.8225 | Val Loss: 1.0631, Val Acc: 0.6935\n",
      "Saved best model at epoch 31 with Val Acc: 0.6935\n",
      "Epoch 32/100 | Train Loss: 0.5168, Train Acc: 0.8258 | Val Loss: 1.0600, Val Acc: 0.7018\n",
      "Saved best model at epoch 32 with Val Acc: 0.7018\n",
      "Epoch 33/100 | Train Loss: 0.5110, Train Acc: 0.8330 | Val Loss: 1.0237, Val Acc: 0.7171\n",
      "Saved best model at epoch 33 with Val Acc: 0.7171\n",
      "Epoch 34/100 | Train Loss: 0.5075, Train Acc: 0.8347 | Val Loss: 1.3780, Val Acc: 0.6179\n",
      "Epoch 35/100 | Train Loss: 0.4804, Train Acc: 0.8421 | Val Loss: 1.0554, Val Acc: 0.7101\n",
      "Epoch 36/100 | Train Loss: 0.4684, Train Acc: 0.8465 | Val Loss: 1.0244, Val Acc: 0.7295\n",
      "Saved best model at epoch 36 with Val Acc: 0.7295\n",
      "Epoch 37/100 | Train Loss: 0.4734, Train Acc: 0.8443 | Val Loss: 1.1089, Val Acc: 0.7087\n",
      "Epoch 38/100 | Train Loss: 0.4164, Train Acc: 0.8613 | Val Loss: 1.0573, Val Acc: 0.7233\n",
      "Epoch 39/100 | Train Loss: 0.4220, Train Acc: 0.8589 | Val Loss: 1.1693, Val Acc: 0.6963\n",
      "Epoch 40/100 | Train Loss: 0.4011, Train Acc: 0.8682 | Val Loss: 1.0477, Val Acc: 0.7157\n",
      "Epoch 41/100 | Train Loss: 0.3807, Train Acc: 0.8772 | Val Loss: 1.0713, Val Acc: 0.7101\n",
      "Epoch 42/100 | Train Loss: 0.3822, Train Acc: 0.8746 | Val Loss: 1.1222, Val Acc: 0.7067\n",
      "Epoch 43/100 | Train Loss: 0.2628, Train Acc: 0.9132 | Val Loss: 0.8738, Val Acc: 0.7712\n",
      "Saved best model at epoch 43 with Val Acc: 0.7712\n",
      "Epoch 44/100 | Train Loss: 0.2058, Train Acc: 0.9366 | Val Loss: 0.8349, Val Acc: 0.7767\n",
      "Saved best model at epoch 44 with Val Acc: 0.7767\n",
      "Epoch 45/100 | Train Loss: 0.1840, Train Acc: 0.9430 | Val Loss: 0.8153, Val Acc: 0.7767\n",
      "Epoch 46/100 | Train Loss: 0.1733, Train Acc: 0.9482 | Val Loss: 0.8212, Val Acc: 0.7795\n",
      "Saved best model at epoch 46 with Val Acc: 0.7795\n",
      "Epoch 47/100 | Train Loss: 0.1650, Train Acc: 0.9487 | Val Loss: 0.8073, Val Acc: 0.7850\n",
      "Saved best model at epoch 47 with Val Acc: 0.7850\n",
      "Epoch 48/100 | Train Loss: 0.1638, Train Acc: 0.9517 | Val Loss: 0.8106, Val Acc: 0.7753\n",
      "Epoch 49/100 | Train Loss: 0.1536, Train Acc: 0.9554 | Val Loss: 0.7904, Val Acc: 0.7864\n",
      "Saved best model at epoch 49 with Val Acc: 0.7864\n",
      "Epoch 50/100 | Train Loss: 0.1543, Train Acc: 0.9541 | Val Loss: 0.8044, Val Acc: 0.7864\n",
      "Epoch 51/100 | Train Loss: 0.1413, Train Acc: 0.9593 | Val Loss: 0.7905, Val Acc: 0.7913\n",
      "Saved best model at epoch 51 with Val Acc: 0.7913\n",
      "Epoch 52/100 | Train Loss: 0.1416, Train Acc: 0.9600 | Val Loss: 0.8001, Val Acc: 0.7906\n",
      "Epoch 53/100 | Train Loss: 0.1287, Train Acc: 0.9633 | Val Loss: 0.8175, Val Acc: 0.7933\n",
      "Saved best model at epoch 53 with Val Acc: 0.7933\n",
      "Epoch 54/100 | Train Loss: 0.1310, Train Acc: 0.9620 | Val Loss: 0.8142, Val Acc: 0.7836\n",
      "Epoch 55/100 | Train Loss: 0.1247, Train Acc: 0.9636 | Val Loss: 0.8343, Val Acc: 0.7802\n",
      "Epoch 56/100 | Train Loss: 0.1259, Train Acc: 0.9632 | Val Loss: 0.8178, Val Acc: 0.7885\n",
      "Epoch 57/100 | Train Loss: 0.1251, Train Acc: 0.9629 | Val Loss: 0.8344, Val Acc: 0.7788\n",
      "Epoch 58/100 | Train Loss: 0.1258, Train Acc: 0.9641 | Val Loss: 0.8119, Val Acc: 0.7857\n",
      "Epoch 59/100 | Train Loss: 0.1202, Train Acc: 0.9648 | Val Loss: 0.8199, Val Acc: 0.7864\n",
      "Epoch 60/100 | Train Loss: 0.1096, Train Acc: 0.9694 | Val Loss: 0.8235, Val Acc: 0.7864\n",
      "Epoch 61/100 | Train Loss: 0.1176, Train Acc: 0.9658 | Val Loss: 0.8178, Val Acc: 0.7892\n",
      "Epoch 62/100 | Train Loss: 0.1083, Train Acc: 0.9702 | Val Loss: 0.8194, Val Acc: 0.7878\n",
      "Epoch 63/100 | Train Loss: 0.1101, Train Acc: 0.9685 | Val Loss: 0.8328, Val Acc: 0.7857\n",
      "Early stopping triggered at epoch 63. No improvement in validation accuracy for 10 epochs.\n"
     ]
    }
   ],
   "source": [
    "trainer.train(num_epochs=100, save_path='100_model_opt.pth', resume=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
