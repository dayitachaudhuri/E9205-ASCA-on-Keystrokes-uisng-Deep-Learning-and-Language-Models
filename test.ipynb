{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AudioKeystrokeDataset.AudioKeystrokeDataset import AudioKeystrokeDataset\n",
    "from CoatNet.CoatNet import CoAtNet\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "DATASET_PATH = config['DATASET_PATH']['mac']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Dataset fot Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Audio Files: 100%|██████████| 61/61 [00:31<00:00,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'(.).wav': 0, '0.wav': 1, '1.wav': 2, '2.wav': 3, '3.wav': 4, '4.wav': 5, '5.wav': 6, '6.wav': 7, '7.wav': 8, '8.wav': 9, '9.wav': 10, 'Lalt.wav': 11, 'Lcmd.wav': 12, 'Lctrl.wav': 13, 'Lshift.wav': 14, 'Ralt.wav': 15, 'Rshift.wav': 16, 'a.wav': 17, \"apostrophe(').wav\": 18, 'b.wav': 19, 'backslash.wav': 20, 'bracketclose(]).wav': 21, 'bracketopen([).wav': 22, 'c.wav': 23, 'caps.wav': 24, 'd.wav': 25, 'delete.wav': 26, 'down.wav': 27, 'e.wav': 28, 'enter.wav': 29, 'equal(=).wav': 30, 'esc.wav': 31, 'f.wav': 32, 'fn.wav': 33, 'g.wav': 34, 'h.wav': 35, 'i.wav': 36, 'j.wav': 37, 'k.wav': 38, 'l.wav': 39, 'left.wav': 40, 'm.wav': 41, 'n.wav': 42, 'o.wav': 43, 'p.wav': 44, 'q.wav': 45, 'r.wav': 46, 'right.wav': 47, 's.wav': 48, 'slash.wav': 49, 'space.wav': 50, 'start.wav': 51, 't.wav': 52, 'tab.wav': 53, 'u.wav': 54, 'up.wav': 55, 'v.wav': 56, 'w.wav': 57, 'x.wav': 58, 'y.wav': 59, 'z.wav': 60}\n",
      "Dataset contains 2132 keystroke samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = AudioKeystrokeDataset(DATASET_PATH)\n",
    "print(f\"Dataset contains {len(dataset)} keystroke samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1705\n",
      "Validation dataset size: 427\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = CoAtNet(num_classes=61)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.2954\n",
      "Epoch [2/10], Loss: 4.1424\n",
      "Epoch [3/10], Loss: 4.1304\n",
      "Epoch [4/10], Loss: 4.1230\n",
      "Epoch [5/10], Loss: 4.1215\n",
      "Validation Accuracy: 0.0094\n",
      "Epoch [6/10], Loss: 4.1187\n",
      "Epoch [7/10], Loss: 4.1189\n",
      "Epoch [8/10], Loss: 4.1153\n",
      "Epoch [9/10], Loss: 4.1152\n",
      "Epoch [10/10], Loss: 4.1152\n",
      "Validation Accuracy: 0.0094\n",
      "Epoch [11/10], Loss: 4.1121\n",
      "Epoch [12/10], Loss: 4.1068\n",
      "Epoch [13/10], Loss: 4.0994\n",
      "Epoch [14/10], Loss: 4.0918\n",
      "Epoch [15/10], Loss: 4.0809\n",
      "Validation Accuracy: 0.0211\n",
      "Epoch [16/10], Loss: 4.0611\n",
      "Epoch [17/10], Loss: 4.0496\n",
      "Epoch [18/10], Loss: 4.0182\n",
      "Epoch [19/10], Loss: 3.9999\n",
      "Epoch [20/10], Loss: 3.9453\n",
      "Validation Accuracy: 0.0328\n",
      "Epoch [21/10], Loss: 3.8980\n",
      "Epoch [22/10], Loss: 3.8839\n",
      "Epoch [23/10], Loss: 3.8473\n",
      "Epoch [24/10], Loss: 3.7900\n",
      "Epoch [25/10], Loss: 3.7283\n",
      "Validation Accuracy: 0.0492\n",
      "Epoch [26/10], Loss: 3.7060\n",
      "Epoch [27/10], Loss: 3.6727\n",
      "Epoch [28/10], Loss: 3.6532\n",
      "Epoch [29/10], Loss: 3.6130\n",
      "Epoch [30/10], Loss: 3.6029\n",
      "Validation Accuracy: 0.0562\n",
      "Epoch [31/10], Loss: 3.5671\n",
      "Epoch [32/10], Loss: 3.5244\n",
      "Epoch [33/10], Loss: 3.5322\n",
      "Epoch [34/10], Loss: 3.4401\n",
      "Epoch [35/10], Loss: 3.4448\n",
      "Validation Accuracy: 0.0796\n",
      "Epoch [36/10], Loss: 3.4253\n",
      "Epoch [37/10], Loss: 3.3801\n",
      "Epoch [38/10], Loss: 3.3782\n",
      "Epoch [39/10], Loss: 3.3269\n",
      "Epoch [40/10], Loss: 3.3039\n",
      "Validation Accuracy: 0.0726\n",
      "Epoch [41/10], Loss: 3.3051\n",
      "Epoch [42/10], Loss: 3.2564\n",
      "Epoch [43/10], Loss: 3.2398\n",
      "Epoch [44/10], Loss: 3.1999\n",
      "Epoch [45/10], Loss: 3.1955\n",
      "Validation Accuracy: 0.1030\n",
      "Epoch [46/10], Loss: 3.1799\n",
      "Epoch [47/10], Loss: 3.1454\n",
      "Epoch [48/10], Loss: 3.1287\n",
      "Epoch [49/10], Loss: 3.1105\n",
      "Epoch [50/10], Loss: 3.1063\n",
      "Validation Accuracy: 0.0937\n",
      "Epoch [51/10], Loss: 3.1055\n",
      "Epoch [52/10], Loss: 3.0243\n",
      "Epoch [53/10], Loss: 3.0142\n",
      "Epoch [54/10], Loss: 2.9606\n",
      "Epoch [55/10], Loss: 2.9688\n",
      "Validation Accuracy: 0.0984\n",
      "Epoch [56/10], Loss: 2.9580\n",
      "Epoch [57/10], Loss: 2.9335\n",
      "Epoch [58/10], Loss: 2.9263\n",
      "Epoch [59/10], Loss: 2.9247\n",
      "Epoch [60/10], Loss: 2.9081\n",
      "Validation Accuracy: 0.1030\n",
      "Epoch [61/10], Loss: 2.8522\n",
      "Epoch [62/10], Loss: 2.8693\n",
      "Epoch [63/10], Loss: 2.8079\n",
      "Epoch [64/10], Loss: 2.8086\n",
      "Epoch [65/10], Loss: 2.7958\n",
      "Validation Accuracy: 0.1288\n",
      "Epoch [66/10], Loss: 2.7510\n",
      "Epoch [67/10], Loss: 2.7404\n",
      "Epoch [68/10], Loss: 2.6988\n",
      "Epoch [69/10], Loss: 2.6887\n",
      "Epoch [70/10], Loss: 2.6825\n",
      "Validation Accuracy: 0.1358\n",
      "Epoch [71/10], Loss: 2.6112\n",
      "Epoch [72/10], Loss: 2.5986\n",
      "Epoch [73/10], Loss: 2.5892\n",
      "Epoch [74/10], Loss: 2.5573\n",
      "Epoch [75/10], Loss: 2.5403\n",
      "Validation Accuracy: 0.1194\n",
      "Epoch [76/10], Loss: 2.5505\n",
      "Epoch [77/10], Loss: 2.4842\n",
      "Epoch [78/10], Loss: 2.4377\n",
      "Epoch [79/10], Loss: 2.4408\n",
      "Epoch [80/10], Loss: 2.4148\n",
      "Validation Accuracy: 0.1569\n",
      "Epoch [81/10], Loss: 2.3815\n",
      "Epoch [82/10], Loss: 2.3288\n",
      "Epoch [83/10], Loss: 2.3235\n",
      "Epoch [84/10], Loss: 2.2687\n",
      "Epoch [85/10], Loss: 2.3337\n",
      "Validation Accuracy: 0.1429\n",
      "Epoch [86/10], Loss: 2.2140\n",
      "Epoch [87/10], Loss: 2.2089\n",
      "Epoch [88/10], Loss: 2.2152\n",
      "Epoch [89/10], Loss: 2.1519\n",
      "Epoch [90/10], Loss: 2.1524\n",
      "Validation Accuracy: 0.1639\n",
      "Epoch [91/10], Loss: 2.0887\n",
      "Epoch [92/10], Loss: 2.0814\n",
      "Epoch [93/10], Loss: 2.0867\n",
      "Epoch [94/10], Loss: 2.0349\n",
      "Epoch [95/10], Loss: 2.0079\n",
      "Validation Accuracy: 0.1686\n",
      "Epoch [96/10], Loss: 2.0418\n",
      "Epoch [97/10], Loss: 2.0153\n",
      "Epoch [98/10], Loss: 1.9424\n",
      "Epoch [99/10], Loss: 1.9071\n",
      "Epoch [100/10], Loss: 1.9029\n",
      "Validation Accuracy: 0.1546\n",
      "Epoch [101/10], Loss: 1.8687\n",
      "Epoch [102/10], Loss: 1.8979\n",
      "Epoch [103/10], Loss: 1.8409\n",
      "Epoch [104/10], Loss: 1.7976\n",
      "Epoch [105/10], Loss: 1.8016\n",
      "Validation Accuracy: 0.1429\n",
      "Epoch [106/10], Loss: 1.7785\n",
      "Epoch [107/10], Loss: 1.7899\n",
      "Epoch [108/10], Loss: 1.7533\n",
      "Epoch [109/10], Loss: 1.7850\n",
      "Epoch [110/10], Loss: 1.7251\n",
      "Validation Accuracy: 0.1663\n",
      "Epoch [111/10], Loss: 1.6570\n",
      "Epoch [112/10], Loss: 1.6939\n",
      "Epoch [113/10], Loss: 1.6335\n",
      "Epoch [114/10], Loss: 1.6412\n",
      "Epoch [115/10], Loss: 1.6663\n",
      "Validation Accuracy: 0.1686\n",
      "Epoch [116/10], Loss: 1.5922\n",
      "Epoch [117/10], Loss: 1.5418\n",
      "Epoch [118/10], Loss: 1.5420\n",
      "Epoch [119/10], Loss: 1.4968\n",
      "Epoch [120/10], Loss: 1.5121\n",
      "Validation Accuracy: 0.1663\n",
      "Epoch [121/10], Loss: 1.4862\n",
      "Epoch [122/10], Loss: 1.4857\n",
      "Epoch [123/10], Loss: 1.4539\n",
      "Epoch [124/10], Loss: 1.4289\n",
      "Epoch [125/10], Loss: 1.4377\n",
      "Validation Accuracy: 0.1733\n",
      "Epoch [126/10], Loss: 1.3765\n",
      "Epoch [127/10], Loss: 1.4111\n",
      "Epoch [128/10], Loss: 1.3777\n",
      "Epoch [129/10], Loss: 1.3366\n",
      "Epoch [130/10], Loss: 1.3299\n",
      "Validation Accuracy: 0.1593\n",
      "Epoch [131/10], Loss: 1.3226\n",
      "Epoch [132/10], Loss: 1.3262\n",
      "Epoch [133/10], Loss: 1.3221\n",
      "Epoch [134/10], Loss: 1.2633\n",
      "Epoch [135/10], Loss: 1.2353\n",
      "Validation Accuracy: 0.1710\n",
      "Epoch [136/10], Loss: 1.2376\n",
      "Epoch [137/10], Loss: 1.2994\n",
      "Epoch [138/10], Loss: 1.2002\n",
      "Epoch [139/10], Loss: 1.1956\n",
      "Epoch [140/10], Loss: 1.1678\n",
      "Validation Accuracy: 0.1452\n",
      "Epoch [141/10], Loss: 1.1838\n",
      "Epoch [142/10], Loss: 1.1821\n",
      "Epoch [143/10], Loss: 1.1482\n",
      "Epoch [144/10], Loss: 1.1740\n",
      "Epoch [145/10], Loss: 1.1187\n",
      "Validation Accuracy: 0.1850\n",
      "Epoch [146/10], Loss: 1.0512\n",
      "Epoch [147/10], Loss: 1.0537\n",
      "Epoch [148/10], Loss: 1.0543\n",
      "Epoch [149/10], Loss: 1.0140\n",
      "Epoch [150/10], Loss: 1.0013\n",
      "Validation Accuracy: 0.1639\n",
      "Epoch [151/10], Loss: 1.0018\n",
      "Epoch [152/10], Loss: 1.0059\n",
      "Epoch [153/10], Loss: 0.9904\n",
      "Epoch [154/10], Loss: 0.9849\n",
      "Epoch [155/10], Loss: 0.9644\n",
      "Validation Accuracy: 0.1546\n",
      "Epoch [156/10], Loss: 0.9691\n",
      "Epoch [157/10], Loss: 0.9250\n",
      "Epoch [158/10], Loss: 0.9064\n",
      "Epoch [159/10], Loss: 0.9384\n",
      "Epoch [160/10], Loss: 0.8852\n",
      "Validation Accuracy: 0.1803\n",
      "Epoch [161/10], Loss: 0.8743\n",
      "Epoch [162/10], Loss: 0.8797\n",
      "Epoch [163/10], Loss: 0.8691\n",
      "Epoch [164/10], Loss: 0.8971\n",
      "Epoch [165/10], Loss: 0.8968\n",
      "Validation Accuracy: 0.1616\n",
      "Epoch [166/10], Loss: 0.8411\n",
      "Epoch [167/10], Loss: 0.7991\n",
      "Epoch [168/10], Loss: 0.7765\n",
      "Epoch [169/10], Loss: 0.8027\n",
      "Epoch [170/10], Loss: 0.7618\n",
      "Validation Accuracy: 0.1639\n",
      "Epoch [171/10], Loss: 0.7804\n",
      "Epoch [172/10], Loss: 0.7482\n",
      "Epoch [173/10], Loss: 0.6730\n",
      "Epoch [174/10], Loss: 0.6889\n",
      "Epoch [175/10], Loss: 0.6967\n",
      "Validation Accuracy: 0.1803\n",
      "Epoch [176/10], Loss: 0.7080\n",
      "Epoch [177/10], Loss: 0.6990\n",
      "Epoch [178/10], Loss: 0.6809\n",
      "Epoch [179/10], Loss: 0.6514\n",
      "Epoch [180/10], Loss: 0.6548\n",
      "Validation Accuracy: 0.1827\n",
      "Epoch [181/10], Loss: 0.6219\n",
      "Epoch [182/10], Loss: 0.6705\n",
      "Epoch [183/10], Loss: 0.6140\n",
      "Epoch [184/10], Loss: 0.6461\n",
      "Epoch [185/10], Loss: 0.6390\n",
      "Validation Accuracy: 0.1803\n",
      "Epoch [186/10], Loss: 0.6072\n",
      "Epoch [187/10], Loss: 0.6899\n",
      "Epoch [188/10], Loss: 0.6396\n",
      "Epoch [189/10], Loss: 0.6113\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m     loss.backward()\n\u001b[32m     12\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m avg_loss = running_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[32m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1100):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.unsqueeze(1).float().to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{10}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation every few epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.unsqueeze(1).float().to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        print(f\"Validation Accuracy: {correct / total:.4f}\")\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
